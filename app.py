import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")

@st.cache_resource
def load_model():
    model_path = "./results/BERT_QLoRA"
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()
    return tokenizer, model

def predict_sentiment(text, tokenizer, model):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        pred = torch.argmax(probs, dim=1).item()
    
    labels = {0: "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π", 1: "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π", 2: "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π"}
    return labels[pred], probs[0].numpy()

st.title("üìä –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤")
st.write("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ")

try:
    tokenizer, model = load_model()
    st.success("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except:
    st.error("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞.")
    st.stop()

text_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", height=150)

if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
    if text_input:
        with st.spinner("–ê–Ω–∞–ª–∏–∑..."):
            sentiment, probs = predict_sentiment(text_input, tokenizer, model)
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {sentiment}")
    else:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç")
